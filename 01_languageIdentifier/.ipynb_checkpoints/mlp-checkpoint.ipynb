{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UgM7VEXCdbTX",
    "outputId": "8bc9758e-085b-4d1c-85ea-f5580e96678b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1BTTm7E7hz51"
   },
   "outputs": [],
   "source": [
    "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
    "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtmPp7epxEZ"
   },
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5D8w9zd1c2IJ"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "\n",
    "def load_dataset(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
    "    df.columns = ['tweet', 'label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DNg0hoBsc5wL"
   },
   "outputs": [],
   "source": [
    "df_train_dev = load_dataset(url_train_dev)\n",
    "df_test = load_dataset(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHJz9Unop3tN"
   },
   "source": [
    "# Deal with class imbalance by unifying very rare classes (1 member) and upsampling rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8dBdrBI_d6pD"
   },
   "outputs": [],
   "source": [
    "df_train_dev['label'] = df_train_dev['label'].apply(lambda x: x.strip().lower())\n",
    "df_test['label'] = df_test['label'].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-KSwSCy_OY_r"
   },
   "outputs": [],
   "source": [
    "def unify_singleton_classes(df, threshold):\n",
    "    counts = df['label'].value_counts()\n",
    "    rare_labels = [label for label in counts[counts < threshold].index]\n",
    "    df.loc[(df.label.isin(rare_labels)), 'label'] = 'und'\n",
    "    return df\n",
    "\n",
    "df_train_dev_uni = unify_singleton_classes(df_train_dev, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XdSkUrZueMU1"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def upsample_rare_classes(df, threshold, sample_size):\n",
    "    \"\"\"Copy low frequent Tweets of languages, that have a number \n",
    "    of tweets below a certain threshold.\n",
    "    \n",
    "    :param data_train: dataframe\n",
    "    :param threshold: int\n",
    "    :param sample_size: int\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    classes_to_upsample = set()\n",
    "    for index, row in df.iterrows():\n",
    "        class_counts[row['label']] += 1\n",
    "    for label, count in class_counts.items():\n",
    "        if count < threshold:\n",
    "            classes_to_upsample.add(label)\n",
    "    df_to_upsample = df[df['label'].isin(classes_to_upsample)]\n",
    "    upsampled_classes = pd.DataFrame(resample(df_to_upsample.to_numpy(), replace=True, n_samples=sample_size, random_state=42))\n",
    "    upsampled_classes.columns = ['tweet', 'label']\n",
    "    return pd.concat([df, upsampled_classes]).sample(frac=1)\n",
    "\n",
    "df_train_dev_up = upsample_rare_classes(df=df_train_dev_uni, threshold=50, sample_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Yg7Ot2RWeVHj",
    "outputId": "18d49691-f706-40c5-89e4-ced9bb01b3e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52675, 2)\n",
      "(54675, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.shape)\n",
    "print(df_train_dev_up.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qxb9qeRprB8"
   },
   "source": [
    "# Process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8FwgxNUdngK1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_fitted = LabelEncoder().fit(df_train_dev_up['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2V6JkOLrn-75",
    "outputId": "ad4abcdb-fbd1-4d8d-99c7-2dfe9d1cc8a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# map all classes that are not in train_dev to undefined\n",
    "for i, label in enumerate(df_test['label']):\n",
    "    df_test['label'][i] = 'und' if label not in le_fitted.classes_ else label\n",
    "# check if it worked: should return an empty list\n",
    "print([label for label in df_test['label'] if label not in set(df_train_dev_up['label'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EV6KmRn4oOIF"
   },
   "outputs": [],
   "source": [
    "y_train_dev, y_test = le_fitted.transform(df_train_dev_up['label']), le_fitted.transform(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0gShv_UsLiZ"
   },
   "source": [
    "# Preprocess Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93UMrd5BtL-B"
   },
   "source": [
    "Pipeline classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M6iOls7ib_-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class TweetNormalizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "    def _normalize_tweet(self, tweet):\n",
    "        \"\"\"Remove punctuation and newlines, lowercase, pad with spaces.\n",
    "\n",
    "        :param tweet: string\n",
    "        :return: normalized string\n",
    "        \"\"\"\n",
    "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "        tweet = re.sub(r'\\n', r'', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'@\\w+\\b', r'', tweet)\n",
    "        tweet = re.sub(r'\\b\\S+//\\S+\\b', r'', tweet)\n",
    "        # tweet = ' ' + tweet + ' '\n",
    "        return tweet\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets = []\n",
    "        for tweet in X:\n",
    "            tweets.append(self._normalize_tweet(tweet))\n",
    "        return np.array(tweets)\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    vowels = set([c for c in 'aeiouäöüàéèëï'])\n",
    "    consonants = set([c for c in 'bcdfghklmnlpqrstvwxyz'])\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def _to_bigrams(self, tweet):\n",
    "        return [bg[0] + bg[1] for bg in zip(tweet, tweet[1:])]\n",
    "\n",
    "    def _get_vowel_consonant_ratio(self, tweet):\n",
    "        vf = 0\n",
    "        cf = 0\n",
    "        for c in tweet.lower():\n",
    "            if c in self.vowels:\n",
    "                vf =+ 1\n",
    "            elif c in self.consonants:\n",
    "                cf += 1\n",
    "        return vf / (cf + 1)\n",
    "\n",
    "    def _get_capitalization_ratio(self, tweet):\n",
    "        up_count = 0\n",
    "        for c in tweet:\n",
    "            if c.upper() == c:\n",
    "                up_count += 1\n",
    "        return up_count / (len(tweet) + 1)\n",
    "\n",
    "    def _get_double_char_freq(self, tweet):\n",
    "        double_freq = 0\n",
    "        for bg in self._to_bigrams(tweet):\n",
    "            if bg[0] == bg[1]:\n",
    "                double_freq += 1\n",
    "        return double_freq\n",
    "    \n",
    "    def _extract_num_features(self, tweets):\n",
    "        num_features = []\n",
    "        for tweet in tweets:\n",
    "            feat_tweet = []\n",
    "            feat_tweet.append(self._get_vowel_consonant_ratio(tweet))\n",
    "            feat_tweet.append(self._get_capitalization_ratio(tweet))\n",
    "            feat_tweet.append(self._get_double_char_freq(tweet))\n",
    "            num_features.append(feat_tweet)\n",
    "        return np.array(num_features)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        numerical_features = self._extract_num_features(X)\n",
    "        self.scaler.fit(numerical_features)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        numerical_features= self._extract_num_features(X)\n",
    "        return X, self.scaler.transform(numerical_features)\n",
    "\n",
    "\n",
    "class MatrixToArrayConverter1(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[0].toarray(), X[1]\n",
    "\n",
    "\n",
    "class MatrixUnifier(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.concatenate([X[0].todense(), X[1]], axis=1)\n",
    "\n",
    "\n",
    "class CountVectorizerWrapper:\n",
    "\n",
    "    def __init__(self, ngram_range, analyzer, max_features, binary):\n",
    "        print('args:', str([ngram_range, analyzer, max_features, binary]))\n",
    "        self.countvec = CountVectorizer(ngram_range=ngram_range, analyzer=analyzer, max_features=max_features, binary=binary)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        self.countvec.fit(tweets)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweets, numerical_features = X\n",
    "        return self.countvec.transform(tweets), numerical_features\n",
    "\n",
    "\n",
    "class OneHotEncoderWrapper:\n",
    "\n",
    "    def __init__(self, handle_unknown):\n",
    "        self.ohe = OneHotEncoder(handle_unknown=handle_unknown)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.ohe.fit(X[0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.ohe.transform(X[0]), X[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3gvmuUPtS5j"
   },
   "source": [
    "Helper classes for the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "asuv2Ey8suTF"
   },
   "outputs": [],
   "source": [
    "class GenericClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator):\n",
    "        self.clf = clf\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.clf.score(X, y)\n",
    "\n",
    "\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        import pdb; pdb.set_trace()\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yerRC06qtabm"
   },
   "source": [
    "# GridSearch and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uQq5eigQKi2D"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4pDxK9slayq3"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'CLF__hidden_layer_sizes': (50, 100),\n",
    "    'CLF__max_iter': (20,),\n",
    "    'CLF__activation': ('logistic', 'relu'),\n",
    "    'CLF__solver': ('sgd', 'adam'),\n",
    "    'CLF__early_stopping': (True, False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YOsRd7OoFUWn",
    "outputId": "04073619-ca7e-4563-f7d0-1f7e4a649d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: [(2, 2), 'char_wb', 100, True]\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  18.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.2s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   8.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  15.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.6s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.6s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  12.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.4s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  16.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.2s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.0s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=   9.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.1s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.2s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.9s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.3s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  11.9s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.6s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.5s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  10.4s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.9s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  13.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.5s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.8s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   0.8s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   4.0s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   5.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.7s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.1s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.6s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   1.1s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.2s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   6.8s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.4s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  14.7s\n",
      "[Pipeline] ... (step 1 of 7) Processing TweetNormalizer, total=   2.3s\n",
      "[Pipeline] .. (step 2 of 7) Processing FeatureExtractor, total=   5.8s\n",
      "[Pipeline] .. (step 3 of 7) Processing BigramVectorizer, total=   7.6s\n",
      "[Pipeline]  (step 4 of 7) Processing MatrixToArrayConverter, total=   0.0s\n",
      "[Pipeline] ..... (step 5 of 7) Processing OneHotEncoder, total=   0.5s\n",
      "[Pipeline] ..... (step 6 of 7) Processing MatrixUnifier, total=   0.0s\n",
      "[Pipeline] ............... (step 7 of 7) Processing CLF, total=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('TweetNormalizer', TweetNormalizer()),\n",
       "                                       ('FeatureExtractor', FeatureExtractor()),\n",
       "                                       ('BigramVectorizer',\n",
       "                                        <__main__.CountVectorizerWrapper object at 0x7f5ba894d358>),\n",
       "                                       ('MatrixToArrayConverter',\n",
       "                                        MatrixToArrayConverter1()),\n",
       "                                       ('OneHotEncoder',\n",
       "                                        <__main__.OneHotEncoderWrapper object at 0x7f5ba894d518...\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=True),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'CLF__activation': ('logistic', 'relu'),\n",
       "                         'CLF__early_stopping': (True, False),\n",
       "                         'CLF__hidden_layer_sizes': (50, 100),\n",
       "                         'CLF__max_iter': (20,),\n",
       "                         'CLF__solver': ('sgd', 'adam')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "bigram_vec_args = dict(ngram_range=(2,2), analyzer='char_wb', max_features=100, binary=True)\n",
    "pipe = Pipeline(steps=[\n",
    "    ('TweetNormalizer', TweetNormalizer()),\n",
    "    ('FeatureExtractor', FeatureExtractor()),\n",
    "    ('BigramVectorizer', CountVectorizerWrapper(**bigram_vec_args)),\n",
    "    ('MatrixToArrayConverter', MatrixToArrayConverter1()),\n",
    "    ('OneHotEncoder', OneHotEncoderWrapper(handle_unknown='ignore')),\n",
    "    ('MatrixUnifier', MatrixUnifier()),\n",
    "    ('CLF', MLPClassifier())\n",
    "], verbose=True)\n",
    "grid = GridSearchCV(pipe, n_jobs=1, param_grid=param_grid, scoring='f1_micro', cv=10)\n",
    "grid.fit(df_train_dev_up['tweet'].to_numpy(), y_train_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA3JAYJBDZxy"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZHDby7NB7PW"
   },
   "source": [
    "Micro f1-Score of the naive base models on the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gDOlBtb2B4Nq",
    "outputId": "762a773a-d611-44f7-deca-2b93f3c45a04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([23.29655533, 23.80013883, 28.37692676, 28.94297936, 23.9102855 ,\n",
       "        24.33465533, 29.08181942, 29.76082757, 22.48326707, 23.23607869,\n",
       "        26.20014956, 27.28121769, 23.15511045, 23.85770602, 27.07712088,\n",
       "        27.95471535]),\n",
       " 'mean_score_time': array([0.65281556, 0.64989462, 0.66801858, 0.66540723, 0.6520777 ,\n",
       "        0.65625441, 0.66749249, 0.67079608, 0.65092449, 0.68989036,\n",
       "        0.65476646, 0.65378716, 0.64737597, 0.69298468, 0.65165803,\n",
       "        0.65400846]),\n",
       " 'mean_test_score': array([0.59623236, 0.74820312, 0.61132147, 0.75776885, 0.60541409,\n",
       "        0.75067215, 0.61984453, 0.76053056, 0.69968006, 0.76495655,\n",
       "        0.7096298 , 0.77413811, 0.7055695 , 0.76513954, 0.71347063,\n",
       "        0.77419294]),\n",
       " 'param_CLF__activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__early_stopping': masked_array(data=[True, True, True, True, False, False, False, False,\n",
       "                    True, True, True, True, False, False, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__hidden_layer_sizes': masked_array(data=[50, 50, 100, 100, 50, 50, 100, 100, 50, 50, 100, 100,\n",
       "                    50, 50, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__max_iter': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_CLF__solver': masked_array(data=['sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd',\n",
       "                    'adam', 'sgd', 'adam', 'sgd', 'adam', 'sgd', 'adam',\n",
       "                    'sgd', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'logistic',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': True,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 50,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'sgd'},\n",
       "  {'CLF__activation': 'relu',\n",
       "   'CLF__early_stopping': False,\n",
       "   'CLF__hidden_layer_sizes': 100,\n",
       "   'CLF__max_iter': 20,\n",
       "   'CLF__solver': 'adam'}],\n",
       " 'rank_test_score': array([16,  8, 14,  6, 15,  7, 13,  5, 12,  4, 10,  2, 11,  3,  9,  1],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.58906364, 0.7448793 , 0.60643745, 0.75786394, 0.60040234,\n",
       "        0.75219459, 0.61247257, 0.75658376, 0.69531822, 0.76353328,\n",
       "        0.70482809, 0.77340892, 0.6955011 , 0.76627652, 0.71104609,\n",
       "        0.78054133]),\n",
       " 'split1_test_score': array([0.59747623, 0.74213606, 0.61375274, 0.74945135, 0.60442575,\n",
       "        0.74341624, 0.62362838, 0.75548647, 0.69348939, 0.75713241,\n",
       "        0.70811997, 0.76810534, 0.69970739, 0.7633504 , 0.71269203,\n",
       "        0.76627652]),\n",
       " 'split2_test_score': array([0.59692758, 0.7520117 , 0.61100951, 0.75384053, 0.60844916,\n",
       "        0.75292612, 0.61997074, 0.76316752, 0.70245062, 0.76572787,\n",
       "        0.71214338, 0.77286028, 0.70702268, 0.76298464, 0.71616679,\n",
       "        0.77249451]),\n",
       " 'split3_test_score': array([0.59272129, 0.74506218, 0.61338698, 0.75548647, 0.59784199,\n",
       "        0.74963424, 0.62161668, 0.75804682, 0.69879298, 0.77121434,\n",
       "        0.70409656, 0.77651792, 0.70409656, 0.76353328, 0.70665691,\n",
       "        0.77596928]),\n",
       " 'split4_test_score': array([0.60095099, 0.75128018, 0.61046086, 0.76005852, 0.60040234,\n",
       "        0.75530358, 0.62161668, 0.76079005, 0.70080468, 0.76792246,\n",
       "        0.70958303, 0.77889539, 0.7088515 , 0.76499634, 0.71415508,\n",
       "        0.77688369]),\n",
       " 'split5_test_score': array([0.5963051 , 0.75251509, 0.61002378, 0.75983172, 0.60417048,\n",
       "        0.75251509, 0.62118164, 0.7665996 , 0.70623742, 0.77263581,\n",
       "        0.71282239, 0.77940369, 0.70770075, 0.77684288, 0.72269984,\n",
       "        0.78397659]),\n",
       " 'split6_test_score': array([0.59831718, 0.75452716, 0.61112127, 0.76623377, 0.6149625 ,\n",
       "        0.75105177, 0.62740077, 0.76861167, 0.69946954, 0.76861167,\n",
       "        0.71337114, 0.77885495, 0.70879824, 0.77172124, 0.71446863,\n",
       "        0.77172124]),\n",
       " 'split7_test_score': array([0.60160966, 0.74922261, 0.61075544, 0.7607463 , 0.60746296,\n",
       "        0.75544174, 0.62154747, 0.75800256, 0.70093287, 0.76220962,\n",
       "        0.70568868, 0.77226998, 0.70916408, 0.76495336, 0.71044449,\n",
       "        0.77080666]),\n",
       " 'split8_test_score': array([0.59282971, 0.74556429, 0.61477959, 0.75635632, 0.60856045,\n",
       "        0.74428389, 0.61203585, 0.76092921, 0.70184745, 0.76330712,\n",
       "        0.71117615, 0.77117249, 0.70843241, 0.75708798, 0.7106274 ,\n",
       "        0.77044083]),\n",
       " 'split9_test_score': array([0.59612219, 0.74483263, 0.6114871 , 0.75781965, 0.60746296,\n",
       "        0.74995427, 0.61697457, 0.75708798, 0.69745747, 0.7572709 ,\n",
       "        0.71446863, 0.76989208, 0.70642034, 0.7596488 , 0.71574904,\n",
       "        0.77281873]),\n",
       " 'std_fit_time': array([0.85703263, 0.83433603, 1.44428387, 0.69126093, 0.26800994,\n",
       "        0.76782071, 1.1597015 , 0.74206958, 0.72983914, 0.96774208,\n",
       "        0.75160855, 1.25366329, 0.78340658, 0.99839835, 0.7571704 ,\n",
       "        0.77290599]),\n",
       " 'std_score_time': array([0.0897413 , 0.08868677, 0.09366484, 0.08782298, 0.09372915,\n",
       "        0.09368283, 0.09472961, 0.08925465, 0.08830581, 0.13412298,\n",
       "        0.09002323, 0.09103357, 0.09664738, 0.16853254, 0.08848177,\n",
       "        0.08879921]),\n",
       " 'std_test_score': array([0.00364515, 0.00399557, 0.00221132, 0.00426435, 0.00478304,\n",
       "        0.00387542, 0.00453825, 0.00418029, 0.00348322, 0.00503449,\n",
       "        0.00357493, 0.00383592, 0.00433126, 0.00535757, 0.00411407,\n",
       "        0.00495494])}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcqrfTK1Bcxd"
   },
   "source": [
    "F1-micro and f1-macro score of the best mlp model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "eIlAIaVnNHOU",
    "outputId": "c61dac9a-84f7-4729-c145-1987e7b5c5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro-score on the testset: 0.7888395210482717\n",
      "F1-macro-score on the testset: 0.2545447747657814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "preds = grid.predict(df_test['tweet'].to_numpy())\n",
    "f1_micro = f1_score(preds, y_test, average='micro')\n",
    "f1_macro = f1_score(preds, y_test, average='macro')\n",
    "print(f'F1-micro-score on the testset: {f1_micro}')\n",
    "print(f'F1-macro-score on the testset: {f1_macro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kqDIw95Nsr2"
   },
   "source": [
    "Let's check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T55T709XFkQq",
    "outputId": "9c659d0b-91d9-4496-fcc1-f24647884767"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ar</th>\n",
       "      <th>ar_latn</th>\n",
       "      <th>bn</th>\n",
       "      <th>bs</th>\n",
       "      <th>ca</th>\n",
       "      <th>cs</th>\n",
       "      <th>da</th>\n",
       "      <th>de</th>\n",
       "      <th>el</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fa</th>\n",
       "      <th>fi</th>\n",
       "      <th>fr</th>\n",
       "      <th>gl</th>\n",
       "      <th>he</th>\n",
       "      <th>hi</th>\n",
       "      <th>hi-latn</th>\n",
       "      <th>hr</th>\n",
       "      <th>hu</th>\n",
       "      <th>id</th>\n",
       "      <th>it</th>\n",
       "      <th>ja</th>\n",
       "      <th>jv</th>\n",
       "      <th>ko</th>\n",
       "      <th>ms</th>\n",
       "      <th>ne</th>\n",
       "      <th>nl</th>\n",
       "      <th>no</th>\n",
       "      <th>pl</th>\n",
       "      <th>pt</th>\n",
       "      <th>ro</th>\n",
       "      <th>ru</th>\n",
       "      <th>sq</th>\n",
       "      <th>sr</th>\n",
       "      <th>su</th>\n",
       "      <th>sv</th>\n",
       "      <th>sw</th>\n",
       "      <th>ta</th>\n",
       "      <th>th</th>\n",
       "      <th>tl</th>\n",
       "      <th>tr</th>\n",
       "      <th>uk</th>\n",
       "      <th>und</th>\n",
       "      <th>ur</th>\n",
       "      <th>ur_latn</th>\n",
       "      <th>vi</th>\n",
       "      <th>zh-cn</th>\n",
       "      <th>zh-tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar_latn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4374</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1215</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi-latn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ja</th>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2307</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ko</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>532</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ro</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ta</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>und</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ur_latn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-cn</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-tw</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ar  ar_latn  bn  bs  ca  cs  ...  und  ur  ur_latn  vi  zh-cn  zh-tw\n",
       "ar       153        0   0   0   0   0  ...    7   1        0   0      0      1\n",
       "ar_latn    0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "bn         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "bs         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ca         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "cs         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "da         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "de         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "el         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "en         3        2   0   0   1   0  ...  214   0        1   0      0      0\n",
       "es         0        0   0   0   2   0  ...   71   0        0   0      0      0\n",
       "fa         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "fi         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "fr         0        0   0   0   0   0  ...   10   0        0   0      0      0\n",
       "gl         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "he         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hi         0        0   0   0   0   0  ...    0   1        0   0      0      0\n",
       "hi-latn    0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "hr         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "hu         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "id         0        0   0   0   0   0  ...   78   0        0   2      0      0\n",
       "it         0        0   0   0   0   0  ...    3   0        0   0      0      0\n",
       "ja       364        0   0   0   0   0  ...  100   2        0   0      1      3\n",
       "jv         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ko         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ms         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "ne         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "nl         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "no         0        0   0   0   0   0  ...    2   0        0   0      0      0\n",
       "pl         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "pt         0        0   0   1   0   1  ...   39   0        0   0      0      0\n",
       "ro         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ru         0        0   0   0   0   0  ...   20   0        0   0      0      0\n",
       "sq         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "sr         0        0   0   0   0   0  ...    2   0        0   0      0      0\n",
       "su         0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "sv         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "sw         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ta         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "th         0        0   0   0   0   0  ...    0   1        0   0      0      0\n",
       "tl         0        0   0   0   0   0  ...    3   0        0   0      0      0\n",
       "tr         0        0   0   0   0   0  ...   16   0        0   0      0      0\n",
       "uk         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "und        9        1   0   0   0   0  ...  677   0        0   1      0      0\n",
       "ur         0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "ur_latn    0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "vi         0        0   0   0   0   0  ...    0   0        0   2      0      0\n",
       "zh-cn      0        0   0   0   0   0  ...    1   0        0   0      0      0\n",
       "zh-tw      0        0   0   0   0   0  ...    0   0        0   0      0      0\n",
       "\n",
       "[49 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(le_fitted.classes_)\n",
    "def create_confusion_matrix(num_classes, preds, y_test):\n",
    "    \"\"\"Create confusion matrix 'by hand' since test set does not contain all labels (thanks to Sarah Kiener).\"\"\"\n",
    "    df = pd.DataFrame(np.zeros((num_classes, num_classes), dtype=int))\n",
    "    for i, j in zip(preds, y_test):\n",
    "        df.iloc[i, j] += 1\n",
    "    df.columns = le_fitted.classes_\n",
    "    df.index = le_fitted.classes_\n",
    "    return df\n",
    "df = create_confusion_matrix(num_classes, preds, y_test)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex01_mlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
